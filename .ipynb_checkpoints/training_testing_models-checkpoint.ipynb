{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': True, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# all requitred imports for this notebook and model definitions\n",
    "# and an explanation of how to load models from /models folder\n",
    "# RUN THIS CELL FIRST\n",
    "# AND THEN CELL \" required functions \"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#models\n",
    "#***** \n",
    "# to see what are the training parameters of the models\n",
    "# previously selected\n",
    "# in svmÂ´s models probability=True to see Plattâ€™s Probabilistic Outputs\n",
    "# catboost by default outputs probabilities\n",
    "#*****\n",
    "rs = 42 \n",
    "# WClassVL SVM linear Cation / Anion\n",
    "linear_cat = SVC(kernel=\"linear\", C=10, random_state= rs, probability=True)\n",
    "linear_an = SVC(kernel=\"linear\", C=10, random_state = rs, probability=True)\n",
    "\n",
    "# WClassVP SVM Poly Cation / Anion\n",
    "poly_cat = SVC(kernel=\"poly\", degree=3, C=10, random_state=rs, probability=True)\n",
    "poly_an = SVC(kernel=\"poly\", degree=3, C=10, random_state=rs, probability=True)\n",
    "\n",
    "# WClassVR SVM RBF Cation / Anion\n",
    "rbf_cat = SVC(kernel=\"rbf\", C=10, gamma=0.1, random_state=rs, probability=True)\n",
    "rbf_an = SVC(kernel=\"rbf\", C=10, gamma=0.01, random_state=rs, probability=True)\n",
    "\n",
    "# WClassCB catboost Cation/Anion\n",
    "cb_cat = OneVsRestClassifier(CatBoostClassifier(iterations=2000, learning_rate=0.1, depth=4,random_state=rs))\n",
    "cb_an = OneVsRestClassifier(CatBoostClassifier(iterations=2000, learning_rate=0.1, depth=4,random_state=rs))\n",
    "\n",
    "# train this models with X_train, y_cat, y_an using .fit(x,y)\n",
    "# **********************************\n",
    "# but!\n",
    "# models are already trained with training database\n",
    "# they are saved in ./models folder\n",
    "# file names in ./models folder\n",
    "# cb_anion\n",
    "# cb_cation\n",
    "# linear_cation\n",
    "# linear_anion\n",
    "# poly_cation\n",
    "# poly_anion\n",
    "# rbf_cation\n",
    "# rbf_anion\n",
    "# **********************************\n",
    "#\n",
    "# example of how to load a model\n",
    "example_model = load(\"models/WClassVL_cation\")\n",
    "print(example_model.get_params())\n",
    "#\n",
    "\n",
    "## requited variables\n",
    "models_cat = np.array([\"WClassCB_cation\", \n",
    "              \"WClassVL_cation\",\n",
    "              \"WClassVP_cation\", \n",
    "              \"WClassVR_cation\"])\n",
    "models_an = np.array([\"WClassCB_anion\", \n",
    "             \"WClassVL_anion\", \n",
    "             \"WClassVP_anion\"\n",
    "            ,\"WClassVR_anion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 9321\n"
     ]
    }
   ],
   "source": [
    "print(\"Version 9321 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of training set and labels (50000, 7) (50000, 1) (50000, 1)\n",
      "shapes of external validation set and labels (8000, 7) (8000, 1) (8000, 1)\n"
     ]
    }
   ],
   "source": [
    "# This blocks load databases into traing and test (external validation)\n",
    "# the user can fir the previous declared models to train with the .fit(function)\n",
    "# random state is set to 42 for consistency.\n",
    "\n",
    "# load training database for ML models\n",
    "train = models_database(\"ML_files/csv_train.csv\")\n",
    "X_train, y_cat, y_an = getXY(train)\n",
    "print(\"shapes of training set and labels\", X_train.shape, y_cat.shape, y_an.shape)\n",
    "\n",
    "# load training database for ML models\n",
    "test = models_database(\"ML_files/csv_test.csv\")\n",
    "X_test, yt_cat, yt_an = getXY(test)\n",
    "print(\"shapes of external validation set and labels\", X_test.shape, yt_cat.shape, yt_an.shape)\n",
    "\n",
    "#Uncomment the .fit() lines if you want to train the models youself\n",
    "#WClassCB -> Catboost model fits\n",
    "#cb_cat.fit(X_train, y_cat)\n",
    "#cb_an.fit(X_train, y_an)\n",
    "\n",
    "#WClassVL -> SVM with linear kernel model fits\n",
    "#linear_cat.fit(X_train, y_cat)\n",
    "#linear_an.fit(X_train, y_an)\n",
    "\n",
    "#WClassVP -> SVM with polynomial kernel model fits\n",
    "#poly_cat.fit(X_train, y_cat)\n",
    "#poly_an.fit(X_train, y_an)\n",
    "\n",
    "#WClassVR -> SVM with radial kernel model fits\n",
    "#rbf_cat.fit(X_train, y_cat)\n",
    "#rbf_an.fit(X_trian, y_an)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cation classifiers\n",
      "           accuracy  precision    recall\n",
      "WClassCB   0.997080   0.997072  0.997067\n",
      "WClassVL   0.996680   0.996674  0.996677\n",
      "WClassVP   0.983440   0.983469  0.983435\n",
      "WClassVR   0.989600   0.989581  0.989575\n",
      "WClassHLR  0.923421   0.924048  0.923294\n",
      "\n",
      "\n",
      "Anion classifiers\n",
      "           accuracy  precision    recall\n",
      "WClassCB   0.999620   0.999620  0.999620\n",
      "WClassVL   0.997720   0.997723  0.997717\n",
      "WClassVP   0.993840   0.993853  0.993832\n",
      "WClassVR   0.992600   0.992613  0.992596\n",
      "WClassHLR  0.930377   0.930450  0.930357\n",
      "end of metrics function\n"
     ]
    }
   ],
   "source": [
    "# in variable t define trainig or test to visualice metrics.\n",
    "# \"test\" is for external validation dataset\n",
    "# \"train\" if for trainig dataset\n",
    "t = \"train\"\n",
    "\n",
    "model_signatures = np.array([\"catboost\",\"linear\",\"poly\", \"rbf\"])\n",
    "\n",
    "\n",
    "if t==\"train\":\n",
    "    db = models_database(\"ML_files/csv_\"+t+\".csv\")\n",
    "else:\n",
    "    db = models_f_lda(\"7HLR_files/waterm_\"+t+\".csv\")\n",
    "\n",
    "\n",
    "#Always use this \n",
    "lda1 = read_lda(\"7HLR_files/waterm_\"+t+\".csv\")\n",
    "metrics(db, models_cat, models_an, False,\"_\"+t, lda1, \"macro\", model_signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required functions\n",
    "\n",
    "# get numpy arrays for training models\n",
    "# for X, and y cations , y anions\n",
    "def getXY(df):\n",
    "  Xs = df[[\"hlr2\",\"hlr3\",\"hlr4\",\"hlr5\",\"hlr6\",\"hlr7\",\"hlr8\"]]\n",
    "  ys = df[[\"CationC\"]]\n",
    "  yz = df[[\"AnionC\"]]\n",
    "  return Xs.to_numpy(), ys.to_numpy(), yz.to_numpy()\n",
    "\n",
    "# get features from the models database\n",
    "def models_database(direction):\n",
    "    database = pd.read_csv(direction)\n",
    "    database = database[['hlr2','hlr3','hlr4','hlr5','hlr6','hlr7','hlr8',\"CationC\",\"AnionC\"]]\n",
    "    return database\n",
    "\n",
    "# make metrics graph\n",
    "def graph(x, name):\n",
    "    \n",
    "    plt.style.use(\"ggplot\")\n",
    "    \n",
    "    ages_x = [\"accuracy\", \"precision\", \"recall\"]\n",
    "    \n",
    "    cat_dev_y = x[0]\n",
    "    plt.plot(ages_x, cat_dev_y, label='Catboost')\n",
    "\n",
    "    rbf_dev_y = x[1]\n",
    "    plt.plot(ages_x, rbf_dev_y, label='SVM Linear')\n",
    "\n",
    "    linear_dev_y = x[2]\n",
    "    plt.plot(ages_x, linear_dev_y, label='SVM Polynomial')\n",
    "\n",
    "    poly_dev_y = x[3]\n",
    "    plt.plot(ages_x, poly_dev_y, label='SVM RBF')\n",
    "    \n",
    "    if(x.shape[0]==5):\n",
    "        lda_dev_y = x[4]\n",
    "        plt.plot(ages_x, lda_dev_y, label='7 hlr (LDA)')\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.title(name[1:])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    direct = \"output/\"\n",
    "    plt.savefig(direct+name+'.png')\n",
    "\n",
    "    plt.show()\n",
    "    #\n",
    "\n",
    "# read information of the output report of water MClasys\n",
    "# in order to obtain a dataframe to make table 4.\n",
    "def read_lda(name):\n",
    "    data = pd.read_csv(name)\n",
    "    \n",
    "    data = data[[\" SampleID\",\"CationC\",\"AnionC\",\"FinalC\",\"CationP\",\"CationPH\",\"AnionP\",\"AnionPH\",\"FinalP\",\"FinalPH\",\n",
    "                \"hlr2\",\"hlr3\",\"hlr4\", \"hlr5\",\"hlr6\",\"hlr7\",\"hlr8\",\n",
    "                \"Ca_input (mg/L)\",\"Mg_input (mg/L)\", \"Na_input (mg/L)\", \"K_input (mg/L)\",\n",
    "                \"SO4_input (mg/L)\", \"Cl_input (mg/L)\", \"HCO3_input (mg/L)\", \"CO3_input (mg/L)\",\n",
    "                \"hp_Ca\",\"hp_Mg\",\"hp_Na\",\"hp_K\", \"hp_SO4\",\"hp_Cl\",\"hp_HCO3\",\"hp_CO3\",\n",
    "                 \"Ca mMol/L\",\"Mg mMol/L\",\"Na mMol/L\",\"K mMol/L\",\"SO4 mMol/L\",\"Cl mMol/L\",\"HCO3 mMol/L\",\"CO3 mMol/L\"\n",
    "                ]]\n",
    "    \n",
    "    # obtain original string names for table 4\n",
    "    cationG = data[[\"CationC\"]]# obtain the original string name\n",
    "    data[\"CationG\"] = cationG # set the string name \n",
    "    anionG = data[[\"AnionC\"]]\n",
    "    data[\"AnionG\"] = anionG\n",
    "    cation_predict = data[[\"CationP\"]]\n",
    "    data[\"CationPredict\"] = cation_predict\n",
    "    anion_predict = data[[\"AnionP\"]]\n",
    "    data[\"AnionPredict\"] = anion_predict\n",
    "    \n",
    "    #obtainC\n",
    "    cationC = data[\"CationC\"].map({\"calcium\": 1, \"magnesium\": 2, \"sodium\":3, \"potassium\":4})\n",
    "    anionC = data[\"AnionC\"].map({\"sulfate\": 1, \"chloride\": 2, \"bicarbonate\":3, \"carbonate\":4})\n",
    "    data[[\"CationC\"]] = cationC\n",
    "    data[[\"AnionC\"]] = anionC\n",
    "    \n",
    "    #obtainP\n",
    "    cationP = data[\"CationP\"].map({\"calcium\": 1, \"magnesium\": 2, \"sodium\":3, \"potassium\":4})\n",
    "    anionP = data[\"AnionP\"].map({\"sulfate\": 1, \"chloride\": 2, \"bicarbonate\":3, \"carbonate\":4})\n",
    "    data[[\"CationP\"]] = cationP\n",
    "    data[[\"AnionP\"]] = anionP\n",
    "    \n",
    "    #print(data.shape)\n",
    "    return data\n",
    "\n",
    "\n",
    "def metrics(models_database, cation_models, anion_models, norm, name, lda_database, avg, just_models):\n",
    "    # cations metrics and graph\n",
    "    # getting the cation and anion labels\n",
    "    X_train, y_cat, y_an = getXY(models_database)\n",
    "    \n",
    "    y_c_lda = lda_database[[\"CationC\"]] #getting the LDA info\n",
    "    y_a_lda = lda_database[[\"AnionC\"]]\n",
    "    y_pred_c_lda = lda_database[[\"CationP\"]] # getting the predicted values for the LDA model\n",
    "    y_pred_a_lda = lda_database[[\"AnionP\"]]\n",
    "    # calculating the metrics\n",
    "    acc_c_lda = accuracy_score(y_c_lda, y_pred_c_lda)\n",
    "    acc_a_lda = accuracy_score(y_a_lda, y_pred_a_lda)\n",
    "    \n",
    "    prec_c_lda = precision_score(y_c_lda, y_pred_c_lda, average=avg)\n",
    "    prec_a_lda = precision_score(y_a_lda, y_pred_a_lda, average=avg)\n",
    "    \n",
    "    tech = \"LDA\"\n",
    "    cm_c = confusion(y_c_lda, y_pred_c_lda)\n",
    "    cm_c2 = confusion_normal(y_c_lda, y_pred_c_lda) # the normalized\n",
    "    cm_a = confusion(y_a_lda, y_pred_a_lda)\n",
    "    cm_a2 = confusion_normal(y_a_lda, y_pred_a_lda) # the normalized\n",
    "    #combine lineal and normalized confusion matrices\n",
    "    cm_c = intercalate(cm_c,cm_c2)\n",
    "    cm_a = intercalate(cm_a, cm_a2)\n",
    "    #np.savetxt(\"output/\"+tech+name+\"_cation_cm.csv\", cm_c, delimiter=',', fmt='%s')\n",
    "    #np.savetxt(\"output/\"+tech+name+\"_anion_cm.csv\", cm_a, delimiter=',', fmt='%s')\n",
    "    # uncomment this so save confusion matrix diagonals\n",
    "    \n",
    "    ## add accuracy store of each class into the confuson matrix, you are\n",
    "    # you are going to put it down the confsusion matrix \n",
    "    # accuracies = \n",
    "    \n",
    "    #print(\"to check anion complete\")\n",
    "    #print(np.unique(y_a_lda))\n",
    "    #print(np.unique(y_pred_a_lda))\n",
    "    #print(precision_score(y_a_lda, y_pred_a_lda, average=None))\n",
    "    #print(confusion_matrix(y_a_lda, y_pred_a_lda))\n",
    "    \n",
    "    rec_c_lda = recall_score(y_c_lda, y_pred_c_lda, average=avg)\n",
    "    rec_a_lda = recall_score(y_a_lda, y_pred_a_lda, average=avg)\n",
    "    \n",
    "\n",
    "    if(norm): # Normalice database\n",
    "        X_train = preprocessing.normalize(X_train, norm='l2')\n",
    "        \n",
    "    # for cations    \n",
    "    accuracy_c = np.array(-99)\n",
    "    precision_c = np.array(-99)\n",
    "    recall_c = np.array(-99)\n",
    "    \n",
    "    # for anions\n",
    "    accuracy_a = np.array(-99)\n",
    "    precision_a = np.array(-99)\n",
    "    recall_a = np.array(-99)\n",
    "    \n",
    "    \n",
    "        \n",
    "    #calculate matrics for cations and anions\n",
    "    for c, a, m_name in zip(cation_models, anion_models, just_models):\n",
    "        _model_c = load(\"models/\"+c)\n",
    "        _model_a = load(\"models/\"+a)\n",
    "        \n",
    "        y_pred_c = _model_c.predict(X_train)\n",
    "        y_pred_a = _model_a.predict(X_train)\n",
    "        \n",
    "        #cation     \n",
    "        acc_c = accuracy_score(y_cat, y_pred_c)\n",
    "        prec_c = precision_score(y_cat, y_pred_c, average=avg)\n",
    "        rec_c = recall_score(y_cat,y_pred_c, average=avg)\n",
    "        \n",
    "        #anion\n",
    "        acc_a = accuracy_score(y_an, y_pred_a)\n",
    "        prec_a = precision_score(y_an, y_pred_a, average=avg)\n",
    "        rec_a = recall_score(y_an, y_pred_a, average=avg)\n",
    "        \n",
    "        #cation\n",
    "        accuracy_c = np.append(accuracy_c, acc_c)\n",
    "        precision_c = np.append(precision_c, prec_c)\n",
    "        recall_c = np.append(recall_c, rec_c)\n",
    "        \n",
    "        #anion\n",
    "        accuracy_a = np.append(accuracy_a, acc_a)\n",
    "        precision_a = np.append(precision_a, prec_a)\n",
    "        recall_a = np.append(recall_a, rec_a)\n",
    "        \n",
    "        tech = m_name\n",
    "        #print(\"chek error\", y_cat.shape, y_pred_c.shape)\n",
    "        cm_c = confusion(y_cat, y_pred_c)\n",
    "        cm_c2 = confusion_normal(y_cat, y_pred_c) # the normalized\n",
    "        cm_a = confusion(y_an, y_pred_a)\n",
    "        cm_a2 = confusion_normal(y_an, y_pred_a) # the normalized\n",
    "        # join both confusion matrices\n",
    "        cm_c = intercalate(cm_c,cm_c2)\n",
    "        cm_a = intercalate(cm_a, cm_a2)\n",
    "        #np.savetxt(\"output/\"+tech+name+\"_cation_cm.csv\", cm_c, delimiter=',', fmt='%s')\n",
    "        #np.savetxt(\"output/\"+tech+name+\"_anion_cm.csv\", cm_a, delimiter=',', fmt='%s')\n",
    "        # uncoment this to save confusion matrix information\n",
    "        \n",
    "    #cation LDA\n",
    "    accuracy_c = np.append(accuracy_c, acc_c_lda)\n",
    "    precision_c = np.append(precision_c, prec_c_lda)\n",
    "    recall_c = np.append(recall_c, rec_c_lda)\n",
    "\n",
    "    #anion LDA\n",
    "    accuracy_a = np.append(accuracy_a, acc_a_lda)\n",
    "    precision_a = np.append(precision_a, prec_a_lda)\n",
    "    recall_a = np.append(recall_a, rec_a_lda)\n",
    "        \n",
    "    oll_c =  np.array([accuracy_c, precision_c, recall_c])\n",
    "    oll_c = oll_c[:,1:]\n",
    "    oll_c = oll_c.transpose()\n",
    "    \n",
    "    cationDF = pd.DataFrame(oll_c)\n",
    "    cationDF.columns=[\"accuracy\",\"precision\",\"recall\"]\n",
    "    cationDF.index=[\"WClassCB\",\"WClassVL\",\"WClassVP\",\"WClassVR\",\"WClassHLR\"]\n",
    "    #cationDF.to_csv(\"naturalM/output/\"+name+\"__Cation.csv\")\n",
    "    print(\"Cation classifiers\")\n",
    "    print(cationDF)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    oll_a = np.array([accuracy_a, precision_a, recall_a])\n",
    "    oll_a = oll_a[:, 1:]\n",
    "    oll_a = oll_a.transpose()\n",
    "    anionDF = pd.DataFrame(oll_a)\n",
    "    anionDF.columns=[\"accuracy\",\"precision\",\"recall\"]\n",
    "    anionDF.index=[\"WClassCB\",\"WClassVL\",\"WClassVP\",\"WClassVR\",\"WClassHLR\"]\n",
    "    #anionDF.to_csv(\"naturalM/output/\"+name+\"__Anion.csv\")\n",
    "    print(\"Anion classifiers\")\n",
    "    print(anionDF)\n",
    "    \n",
    "    #uncomment to get the graphs\n",
    "    #graph(oll_c, name+\"__Cation\")\n",
    "    #graph(oll_a, name+\"__Anion\")  \n",
    "    \n",
    "    \n",
    "    every = pd.concat([cationDF, anionDF], axis=1)\n",
    "    every.to_csv(\"output/\"+name+\"_report_cation_anion.csv\")\n",
    "    \n",
    "    print(\"end of metrics function\")\n",
    "\n",
    "def confusion(y, y_pred):\n",
    "    #cm = confusion_matrix(y, y_pred)\n",
    "    #cm = np.vstack((np.unique(y), cm))\n",
    "    #un = np.unique(y)\n",
    "    #un = np.insert(un, 0, 0, axis=0)\n",
    "    #cm = np.column_stack((un,cm))\n",
    "\n",
    "    # diagonal mode\n",
    "    cm = confusion_matrix(y, y_pred).diagonal()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "\n",
    "def confusion_normal(y, y_pred):\n",
    "    #cm = confusion_matrix(y, y_pred)\n",
    "    #cm = cm / cm.astype(np.float).sum(axis=1)\n",
    "    #cm = np.vstack((np.unique(y), cm))\n",
    "    #un = np.unique(y)\n",
    "    #un = np.insert(un, 0, 0, axis=0)\n",
    "    #cm = np.column_stack((un,cm))\n",
    "\n",
    "    #diagonal model\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cm = cm / cm.astype(np.float).sum(axis=1)\n",
    "    cm = cm.diagonal()\n",
    "                                      \n",
    "    return cm\n",
    "\n",
    "def intercalate(a, b):\n",
    "    c = np.array(0)\n",
    "    for i in range(len(a)):\n",
    "        c = np.append(c, a[i])\n",
    "        c = np.append(c, b[i])\n",
    "    return c\n",
    "    \n",
    "def table4(models_database, cation_models, anion_models, lda_database, name_aux): # this would define the desicions as the original metrics function\n",
    "    print(\"table 4 function\")\n",
    "    # getting database info for the models.\n",
    "    X_train, y_cat, y_an = getXY(models_database)\n",
    "    \n",
    "    # getting the simplest information\n",
    "    # getting mgL\n",
    "    mgL = lda_database[[\" SampleID\",\"Ca_input (mg/L)\",\"Mg_input (mg/L)\", \"Na_input (mg/L)\", \"K_input (mg/L)\",\n",
    "                        \"SO4_input (mg/L)\", \"Cl_input (mg/L)\", \"HCO3_input (mg/L)\", \"CO3_input (mg/L)\",\n",
    "                        \"Ca mMol/L\",\"Mg mMol/L\",\"Na mMol/L\",\"K mMol/L\",\"SO4 mMol/L\",\"Cl mMol/L\",\"HCO3 mMol/L\",\"CO3 mMol/L\",\n",
    "                       \"FinalC\",\"hp_Ca\",\"hp_Mg\",\"hp_Na\",\"hp_K\", \"hp_SO4\",\"hp_Cl\",\"hp_HCO3\",\"hp_CO3\",\n",
    "                        \"FinalP\", \"FinalPH\"]]\n",
    "    # finalC to simbols\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"calcium\",\"Ca\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"magnesium\",\"Mg\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"sodium\",\"Na\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"potassium\",\"K\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"sulfate\",\"SO4\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"chloride\",\"Cl\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"bicarbonate\",\"HCO3\")\n",
    "    mgL[\"FinalC\"] = mgL[\"FinalC\"].str.replace(\"carbonate\",\"CO3\")\n",
    "    # final P to simbols\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"calcium\",\"Ca\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"magnesium\",\"Mg\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"sodium\",\"Na\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"potassium\",\"K\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"sulfate\",\"SO4\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"chloride\",\"Cl\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"bicarbonate\",\"HCO3\")\n",
    "    mgL[\"FinalP\"] = mgL[\"FinalP\"].str.replace(\"carbonate\",\"CO3\")\n",
    "    # final ph to simbols\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"calcium\",\"Ca\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"magnesium\",\"Mg\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"sodium\",\"Na\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"potassium\",\"K\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"sulfate\",\"SO4\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"chloride\",\"Cl\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"bicarbonate\",\"HCO3\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\"carbonate\",\"CO3\")\n",
    "    mgL[\"FinalPH\"] = mgL[\"FinalPH\"].str.replace(\" \",\"-\")\n",
    "    \n",
    "    #full = pd.concat([mgL, g_name])\n",
    "    #print(full)\n",
    "    \n",
    "    #cicle for adding the basic and hibrid decision of a model\n",
    "    for c, a, nom in zip(cation_models, anion_models, name_aux):\n",
    "        print(\" \")\n",
    "        print(\"process in: \", c, a)\n",
    "        _model_c = load(\"models/\"+c)# load cation model\n",
    "        _model_a = load(\"models/\"+a)# load anion model\n",
    "        cation_arr, anion_arr = get_basic_hibrid(_model_c, _model_a, X_train)\n",
    "        # concat cation_arr, anion_arr\n",
    "        model_arr = np.concatenate((cation_arr, anion_arr), axis=1)\n",
    "        model_pd = pd.DataFrame(model_arr)\n",
    "        model_pd.columns=[\"Ca_p\", \"Mg_p\", \"Na_p\", \"K_p\", \"basic_c\", \"hibrid_c\",\n",
    "                         \"SO4_p\", \"Cl_p\", \"HCO3_p\", \"CO3_p\", \"basic_a\", \"hibrid_a\"]\n",
    "        # setting the hibrid finals and basic\n",
    "        model_pd[nom+\" (b)\"] = model_pd[\"basic_c\"]+\"-\"+model_pd[\"basic_a\"]\n",
    "        model_pd[nom+\" (b+h)\"] = model_pd[\"hibrid_c\"]+\"-\"+model_pd[\"hibrid_a\"]\n",
    "        model_pd = model_pd.drop(columns=['basic_c', 'hibrid_c', 'basic_a', \"hibrid_a\"])\n",
    "        # dropear algunas cosas\n",
    "        #print(model_arr)\n",
    "        mgL = pd.concat([mgL, model_pd], axis=1)\n",
    "         \n",
    "        #here you will call the method get_basic_hibrid to get the basic_hibrid names.\n",
    "    \n",
    "    mgL = mgL.rename(columns={\" SampleID\": \"identification\", \"FinalC\":\"GMC\",\n",
    "                        \"FinalP\":\"7 hlr (b)\", \"FinalPH\":\"7 hlr (b+h)\"}, errors=\"raise\")    \n",
    "    return mgL\n",
    "    # wich will output\n",
    "    # number, id\n",
    "    # mg/L conc\n",
    "    # greater molar conc (calculated manually)\n",
    "    # basic and hibrid names for all the models (LDA incluided)\n",
    "\n",
    "# the method will come back an array with the FinalP, FinalPH\n",
    "# final predicted and final predicted hibrid\n",
    "def get_basic_hibrid(model_cation, model_anion, x):\n",
    "    x = preprocessing.normalize(x, norm='l2')\n",
    "    cat_prob = model_cation.predict_proba(x)\n",
    "    an_prob = model_anion.predict_proba(x)\n",
    "    cat_names = {1:\"Ca\", 2:\"Mg\", 3:\"Na\", 4:\"K\"}\n",
    "    an_names = {1:\"SO4\", 2:\"Cl\", 3:\"HCO3\", 4:\"CO3\"}\n",
    "    \n",
    "\n",
    "    cat_probs = get_names(cat_prob, cat_names)\n",
    "    an_probs = get_names(an_prob, an_names)\n",
    "    \n",
    "    #np.savetxt(\"naturalM/___probs_cb_cat.csv\", cat_probs, delimiter=\",\" ,fmt='%s')\n",
    "    #np.savetxt(\"naturalM/___probs_cb_an.csv\", an_probs, delimiter=\",\" ,fmt='%s')\n",
    "    \n",
    "    return cat_probs, an_probs\n",
    "    \n",
    "    #max1 = y_prob.argmax(axis=1)\n",
    "    #typp = np.zeros_like(max1)\n",
    "    \n",
    "def get_names(probs, names):\n",
    "    \n",
    "    #getting the basic name\n",
    "    max1 = probs.argmax(axis=1) #this gives the index of the max value\n",
    "    \n",
    "    zp = np.copy(probs) # to copy the array\n",
    "    for n in range(probs.shape[0]): #setting the max1 values to 0\n",
    "        zp[n,max1[n]] = 0\n",
    "        \n",
    "    \n",
    "    max2 = zp.argmax(axis=1)\n",
    "    typp = np.zeros_like(max1)\n",
    "    \n",
    "    for i in range(probs.shape[0]):\n",
    "        pm = probs[i, max1[i]]\n",
    "        pn = probs[i, max2[i]]\n",
    "        \n",
    "        hib = True\n",
    "        if(pm>=0.5 and (pm-pn)>=0.25 and pn<=0.25):\n",
    "            hib = False\n",
    "            \n",
    "        max1[i]= max1[i]+1\n",
    "        max2[i]= max2[i]+1\n",
    "            \n",
    "        if(hib==False):\n",
    "            typp[i] = max1[i]\n",
    "        else:\n",
    "            typp[i] = max1[i]*10 + max2[i]\n",
    "            \n",
    "    str_hib = np.array([\"zero\"])\n",
    "    str_bas = np.array([\"zero\"])\n",
    "    \n",
    "    for i in range(typp.shape[0]):\n",
    "        if(typp[i]>9):\n",
    "            nd = typp[i]%10\n",
    "            st = (typp[i]-nd)/10\n",
    "            str_hib = np.append(str_hib, names[st]+\"-\"+names[nd])\n",
    "            str_bas = np.append(str_bas, names[max1[i]])\n",
    "        else:\n",
    "            # just one digit\n",
    "            str_hib = np.append(str_hib, names[max1[i]])\n",
    "            str_bas = np.append(str_bas, names[max1[i]])\n",
    "\n",
    "            \n",
    "    # delete the first one\n",
    "    str_hib = np.delete(str_hib, 0)\n",
    "    str_bas = np.delete(str_bas, 0)\n",
    "\n",
    "    end  = np.c_[probs, str_bas, str_hib]\n",
    "    \n",
    "    #hib = \"hib\"\n",
    "    #if(pm>=0.5 and (pm-pn)>=0.25 and pn<=0.25):\n",
    "    #hib=\"pure\"\n",
    "    #comeback\n",
    "    \n",
    "    return end\n",
    "\n",
    "def table4_filter(dat):\n",
    "    det = dat[[\"identification\",\"Ca_input (mg/L)\",\"Mg_input (mg/L)\",\"Na_input (mg/L)\",\"K_input (mg/L)\",\n",
    "               \"SO4_input (mg/L)\",\"Cl_input (mg/L)\",\"HCO3_input (mg/L)\",\"CO3_input (mg/L)\",\n",
    "               \"Ca mMol/L\",\"Mg mMol/L\",\"Na mMol/L\",\"K mMol/L\",\"SO4 mMol/L\",\"Cl mMol/L\",\"HCO3 mMol/L\",\"CO3 mMol/L\",\n",
    "               \"GMC\",\"7 hlr (b)\",\"7 hlr (b+h)\",\n",
    "              \"Catboost (b)\",\"Catboost (b+h)\",\n",
    "               \"SVM-L (b)\",\"SVM-L (b+h)\",\n",
    "              \"SVM-P (b)\",\"SVM-P (b+h)\",\n",
    "              \"SVM-RBF (b)\",\"SVM-RBF (b+h)\"]]\n",
    "    \n",
    "    det.rename(columns={'Ca_input (mg/L)':'Ca',\n",
    "                          'Mg_input (mg/L)':'Mg',\n",
    "                          'Na_input (mg/L)':'Na',\n",
    "                          'K_input (mg/L)':'K',\n",
    "                          'SO4_input (mg/L)':'SO4',\n",
    "                          'Cl_input (mg/L)':'Cl',\n",
    "                              'HCO3_input (mg/L)':'HCO3',\n",
    "                              'CO3_input (mg/L)':'CO3',\n",
    "                        \"Ca mMol/L\":\"Ca_mmol\", \"Mg mMol/L\":\"Mg_mmol\", \"Na mMol/L\":\"Na_mmol\", \"K mMol/L\":\"K_mmol\",\n",
    "                        \"SO4 mMol/L\":\"SO4_mmol\", \"Cl mMol/L\":\"Cl_mmol\",\"HCO3 mMol/L\":\"HCO3_mmol\", \"CO3 mMol/L\":\"CO3_mmol\"\n",
    "                             },\n",
    "                     \n",
    "                 inplace=True)\n",
    "    \n",
    "    #print(det[\"FinalC\"])\n",
    "    #det = det[\"FinalC\"].str.replace(\"calcium\",\"Ca\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"magnesium\",\"Mg\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"sodium\",\"Na\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"potassium\",\"K\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"sulfate\",\"SO4\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"chloride\",\"Cl\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"bicarbonate\",\"HCO3\")\n",
    "    #mgL = mgL[\"FinalC\"].str.replace(\"carbonate\",\"CO3\")\n",
    "    \n",
    "    return det\n",
    "    \n",
    "# to obtain models DB from LDA output   \n",
    "def models_f_lda(direction):\n",
    "    # obtain models db\n",
    "    data = pd.read_csv(direction)\n",
    "    data = data[['hlr2','hlr3','hlr4','hlr5','hlr6','hlr7','hlr8',\"CationC\",\"AnionC\"]]\n",
    "  \n",
    "    cation = data[\"CationC\"].map({\"calcium\": 1, \"magnesium\": 2, \"sodium\":3, \"potassium\":4})\n",
    "    data = data.drop([\"CationC\"], axis=1)\n",
    "\n",
    "    anion = data[\"AnionC\"].map({\"sulfate\": 1, \"chloride\": 2, \"bicarbonate\":3, \"carbonate\":4})\n",
    "    data = data.drop([\"AnionC\"], axis=1)\n",
    "\n",
    "    data.insert(7,\"CationC\", cation)\n",
    "    data.insert(8,\"AnionC\", anion)\n",
    "    \n",
    "    # obtain lda db\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
